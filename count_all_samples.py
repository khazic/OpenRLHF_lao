#!/usr/bin/env python3
"""
ç»Ÿè®¡æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰JSONæ–‡ä»¶çš„æ ·æœ¬æ•°
ç”¨æ³•: python count_all_samples.py /path/to/dataset/folder
"""

import json
import os
import sys
from pathlib import Path


def count_samples_in_json(json_file):
    """ç»Ÿè®¡å•ä¸ªJSONæ–‡ä»¶çš„æ ·æœ¬æ•°"""
    try:
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        if isinstance(data, list):
            return len(data), None
        elif isinstance(data, dict):
            return len(data), "å­—å…¸æ ¼å¼ï¼ˆéåˆ—è¡¨ï¼‰"
        else:
            return 0, "æœªçŸ¥æ ¼å¼"
    except Exception as e:
        return 0, f"é”™è¯¯: {str(e)}"


def main(dataset_dir):
    """ç»Ÿè®¡ç›®å½•ä¸‹æ‰€æœ‰JSONæ–‡ä»¶"""
    
    if not os.path.exists(dataset_dir):
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {dataset_dir}")
        sys.exit(1)
    
    # æŸ¥æ‰¾æ‰€æœ‰JSONæ–‡ä»¶
    json_files = sorted(Path(dataset_dir).glob("*.json"))
    
    if not json_files:
        print(f"âŒ åœ¨ {dataset_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°JSONæ–‡ä»¶")
        sys.exit(1)
    
    print("\n" + "="*100)
    print("ğŸ“Š æ•°æ®é›†æ ·æœ¬æ•°ç»Ÿè®¡")
    print("="*100)
    print(f"ç›®å½•: {dataset_dir}")
    print(f"æ‰¾åˆ° {len(json_files)} ä¸ªJSONæ–‡ä»¶")
    print("="*100)
    print()
    
    # åˆ†ç±»ç»Ÿè®¡
    original_files = []  # åŸå§‹æ•°æ®æ–‡ä»¶
    filtered_files = []  # ç­›é€‰åçš„æ–‡ä»¶
    other_files = []     # å…¶ä»–æ–‡ä»¶ï¼ˆall, removedç­‰ï¼‰
    
    total_original_samples = 0
    total_filtered_samples = 0
    
    # è¡¨å¤´
    print(f"{'åºå·':<6} {'æ–‡ä»¶å':<50} {'æ ·æœ¬æ•°':<12} {'å¤‡æ³¨'}")
    print("-"*100)
    
    for idx, json_file in enumerate(json_files, 1):
        filename = json_file.name
        count, error = count_samples_in_json(json_file)
        
        # åˆ†ç±»
        if '_filtered.json' in filename:
            filtered_files.append((filename, count))
            total_filtered_samples += count
            category = "âœ… ç­›é€‰å"
        elif any(x in filename for x in ['_ppl', '_all.json', '_removed.json', '_summary']):
            other_files.append((filename, count))
            category = "ğŸ“Š ä¸­é—´æ–‡ä»¶"
        else:
            original_files.append((filename, count))
            total_original_samples += count
            category = "ğŸ“ åŸå§‹æ•°æ®"
        
        status = error if error else category
        print(f"{idx:<6} {filename:<50} {count:>10}   {status}")
    
    print("-"*100)
    
    # æ±‡æ€»ç»Ÿè®¡
    print("\n" + "="*100)
    print("ğŸ“ˆ æ±‡æ€»ç»Ÿè®¡")
    print("="*100)
    
    if original_files:
        print(f"\nğŸ“ åŸå§‹æ•°æ®é›† ({len(original_files)} ä¸ªæ–‡ä»¶):")
        print(f"   æ€»æ ·æœ¬æ•°: {total_original_samples:,}")
        for filename, count in sorted(original_files, key=lambda x: x[1], reverse=True):
            print(f"      {count:>8,}  {filename}")
    
    if filtered_files:
        print(f"\nâœ… ç­›é€‰åæ•°æ®é›† ({len(filtered_files)} ä¸ªæ–‡ä»¶):")
        print(f"   æ€»æ ·æœ¬æ•°: {total_filtered_samples:,}")
        if total_original_samples > 0:
            retention_rate = total_filtered_samples / total_original_samples * 100
            removed_samples = total_original_samples - total_filtered_samples
            print(f"   ä¿ç•™ç‡: {retention_rate:.1f}%")
            print(f"   åˆ é™¤æ ·æœ¬: {removed_samples:,}")
        for filename, count in sorted(filtered_files, key=lambda x: x[1], reverse=True):
            print(f"      {count:>8,}  {filename}")
    
    if other_files:
        print(f"\nğŸ“Š å…¶ä»–æ–‡ä»¶ ({len(other_files)} ä¸ª):")
        for filename, count in other_files[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            print(f"      {count:>8,}  {filename}")
        if len(other_files) > 5:
            print(f"      ... è¿˜æœ‰ {len(other_files)-5} ä¸ªæ–‡ä»¶")
    
    print("\n" + "="*100)
    
    # ç”Ÿæˆä½¿ç”¨å»ºè®®
    if original_files and not filtered_files:
        print("\nğŸ’¡ æç¤º:")
        print(f"   å‘ç° {len(original_files)} ä¸ªåŸå§‹æ•°æ®é›†ï¼Œå°šæœªè¿›è¡ŒPPLç­›é€‰")
        print(f"   è¿è¡Œä»¥ä¸‹å‘½ä»¤è¿›è¡Œæ‰¹é‡ç­›é€‰:")
        print(f"   bash filter_all_datasets.sh")
    elif filtered_files:
        print("\nğŸ’¡ ç­›é€‰åçš„æ•°æ®é›†å¯ç”¨äºè®­ç»ƒ:")
        for filename, count in filtered_files:
            print(f"   {filename}")
    
    print("="*100 + "\n")


if __name__ == "__main__":
    if len(sys.argv) > 1:
        dataset_dir = sys.argv[1]
    else:
        dataset_dir = "/xfr_ceph_sh/liuchonghan/sft_dataset"
    
    main(dataset_dir)

